#!/usr/bin/perl
use strict;
use warnings;
use Getopt::Long;
use List::Util 'max';
use List::MoreUtils qw(any all);

use feature qw(say state);


my $usage = <<EOF;
$0 [--has c0,c1,...] [--has c2] [--matches expr] ... c3 c4 f(c0) g(c1) ...

    Other available options:
      --noskipempty
      --skipcomments
      --dumpindices
      --dumpawk
      --perl

    --perl processes the data with perl, not awk. Awk is faster and is thus the
    --default. --dumpawk is only meaningful without --perl
EOF

if(! @ARGV)
{
    die $usage;
}

# by default we do skip empty records
my %options = (skipempty => 1);
GetOptions(\%options,
           "has=s@",
           "matches=s@",
           "skipempty!",
           "skipcomments!",
           "dumpindices!",
           "dumpawk!",
           "perl",
           "help") or die($usage);
$options{has}     //= [];
$options{matches} //= [];

if( $options{perl} && $options{dumpawk})
{
    say STDERR "Can't dump the awk script if we're doing stuff in perl";
    die $usage;
}

if( defined $options{help} )
{
    print $usage;
    exit 0;
}

# useful for realtime plots
autoflush STDOUT;

my @cols_want = @ARGV;
my @must_have_col_indices_in;

# parse the , in $options{has}
my @must_have_col_names;
for my $c (@{$options{has}})
{
    push @must_have_col_names, split(/,/,$c)
}

# if no columns requested, just print everything
if( !@cols_want && !@must_have_col_names && !@{$options{matches}} )
{
    while(<STDIN>)
    { print; }
}

my @cols_all_legend;
my @colnames_output;
my %colindices_in;

my @indices_in = ();
my $indices_in_max;


# these are all for transforms: things like rel(a), deg2rad(x) and so on
my @transforms;        # perl functions
my @awk_output_fields; # awk strings representing stuff to print
# awk stanzas for set up any required state. This is for rel() to store the
# initial value and diff() to store the previous value
my ($awk_state_stanzas_before, $awk_state_stanzas_after);


# Loop searching for the legend.
#
# Here instead of using while(<STDIN>) we read one byte at a time. This means
# that as far as the OS is concerned we never read() past our line. And when we
# exec() to awk, all the data is available. This is inefficient, but we only use
# this function to read up to the legend, which is fine.
#
# Note that perl tries to make while(<STDIN>) work by doing an lseek() before we
# exec(), but if we're reading a pipe, this can't work
while(defined ($_ = get_unbuffered_line(*STDIN)))
{
    if(/^##/p)
    {
        print unless $options{skipcomments};
        next;
    }

    if( /^#/p )
    {
        chomp;

        # we got a legend line
        @cols_all_legend = split ' ', ${^POSTMATCH}; # split the field names (sans the #)
        foreach my $idx (0..$#cols_all_legend)
        {
            $colindices_in{$cols_all_legend[$idx]} = $idx;
        }

        # If we weren't asked for particular columns, take them all. This isn't
        # a no-op because we can have --has
        @cols_want = @cols_all_legend unless @cols_want;

        # grab all the column indices
      COLUMN:
        foreach my $col_want (@cols_want)
        {
            my @funcs;

            my $accept = sub
            {
                my @indices_in_here = @_;

                my $Nindices = @indices_in;

                push @colnames_output, @cols_all_legend[@indices_in_here];
                push @indices_in,      @indices_in_here;

                if( !@funcs )
                {
                    push @awk_output_fields, map { '$'.($_+1) } @indices_in_here;
                }
                else
                {
                    # This loop is important. It is possible to push it to later
                    # by doing this instead:
                    #
                    #   push @transforms, [\@indices_in_here, parse_transform_funcs(@funcs) ];
                    #
                    # but then all of @indices_in_here will get a single
                    # transformation subroutine object, and all of its internal
                    # state will be shared, which is NOT what you want. For
                    # instance if we're doing rel(.*time) or something, then the
                    # initial timestamp would be shared. This is wrong.
                    #
                    # The indices here index the OUTPUT columns list
                    foreach my $idx (0..$#indices_in_here)
                    {
                        my $idx_out = $idx + $Nindices;

                        my @perl_funcs         = parse_transform_funcs(@funcs);
                        my $awk_stanzas_after  = pop @perl_funcs;
                        my $awk_stanzas_before = pop @perl_funcs;
                        my $awk_statement      = pop @perl_funcs;

                        push @transforms,        [$idx_out, @perl_funcs ];

                        my $idx_in        =  $indices_in_here[$idx];
                        $awk_statement    =~ s/___input___/'$'.($idx_in+1)/ge;
                        push @awk_output_fields, $awk_statement;

                        if(defined $awk_stanzas_before)
                        {
                            $awk_stanzas_before      =~ s/___input___/'$'.($idx_in+1)/ge;
                            $awk_state_stanzas_before .= $awk_stanzas_before;
                        }
                        if(defined $awk_stanzas_after)
                        {
                            $awk_stanzas_after      =~ s/___input___/'$'.($idx_in+1)/ge;
                            $awk_state_stanzas_after .= $awk_stanzas_after;
                        }

                        $colnames_output[$idx_out] =
                          join('', map { "$_("} reverse @funcs) .
                          $colnames_output[$idx_out] .
                          ')' x scalar(@funcs);
                    }
                }
            };


            my @indices_in_here;

            # do I have an exact column match?
            @indices_in_here = grep {$col_want eq $cols_all_legend[$_]} 0..$#cols_all_legend;
            if ( @indices_in_here > 1 )
            {
                die "Found more than one column that string-matched '$col_want' exactly";
            }
            if ( @indices_in_here == 1 )
            {
                $accept->(@indices_in_here);
                next;
            }

            # I look for any requested functions. These all look like "f(x)" and
            # may be nested. f(g(h(x))) is allowed. At each function level, I
            # look for exact matching columns. I.e. if I'm asked about
            # "diff(rel(x))" it is possible that I should find a column "x" and
            # then rel() it and then diff() it; it's also possible that I should
            # find a column "rel(x)" and then diff() it
            while($col_want =~ /^           # start
                                ( [^\(]+ )  # Function name. Non-( characters
                                \( (.+) \)  # Function arg
                                $           # End
                               /x)
            {
                unshift @funcs, $1;
                $col_want = $2;

                # do I have an exact column match now?
                @indices_in_here = grep {$col_want eq $cols_all_legend[$_]} 0..$#cols_all_legend;
                if ( @indices_in_here > 1 )
                {
                    die "Found more than one column that string-matched '$col_want' exactly";
                }
                if ( @indices_in_here == 1 )
                {
                    $accept->(@indices_in_here);
                    next COLUMN;
                }

            }

            # I'm done looking for transformations, and no exact matches were
            # found. I know there aren't any more '()' in the string, so I try a
            # regex
            @indices_in_here = grep {$cols_all_legend[$_] =~ qr/$col_want/} 0..$#cols_all_legend;
            if( @indices_in_here >= 1 )
            {
                $accept->(@indices_in_here);
                next;
            }

            die "Couldn't find requested column '$col_want' in the legend line '$_'";
        }

        $indices_in_max = max @indices_in;

        if ( $options{dumpindices} )
        {
            print "@indices_in\n";
            exit;
        }

        # print out the new legend
        print "# @colnames_output\n" unless $options{dumpawk};


        if( @must_have_col_names )
        {
            foreach my $col (@must_have_col_names)
            {
                if( !defined $colindices_in{$col})
                {
                    die "I don't have column '$col'";
                }
                push @must_have_col_indices_in, $colindices_in{$col};
            }
        }
        last;
    }

    die "Got data line before a legend";
}

# data loop
#
# At this point I'm done dealing with the legend, and it's time to read in and
# process the data. I can keep going in perl, or I can generate an awk program,
# and let awk do this work. The reason: awk (mawk especialy) runs much faster.
# Both paths should produce the exact same output, and the test suite makes sure
# this is the case

if( !$options{perl} )
{
    my $awkprogram = makeAwkProgram();
    if( $options{dumpawk} )
    {
        say $awkprogram;
        exit;
    }
    exec 'mawk', $awkprogram;
    exit; # dummy. We never get here
}

my $must_match_expr =
  join ' && ', map {
      s/(\w+)/defined $colindices_in{$1} ? '$f[' . $colindices_in{$1} . ']' : $1/egr
  } @{$options{matches}};


RECORD:
while(<STDIN>)
{
    # Data loop. Each statement here is analogous to the awk program generated
    # by makeAwkProgram();

    # skip comments
    if(/^#/)
    {
        print unless $options{skipcomments};
        next;
    }

    chomp;
    my @f = split;

    # skip incomplete records. Can happen if a log line at the end of a file was
    # cut off in the middle
    next unless $indices_in_max <= $#f;

    # skip records that have empty input columns that must be non-empty
    next if any {'-' eq $f[$_]} @must_have_col_indices_in;

    # skip all records that don't match given expressions
    next if $must_match_expr && !eval $must_match_expr;


    @f = @f[@indices_in];

    # skip empty records if we must
    next if $options{skipempty} && all {$_ eq '-' } @f;

    # apply transformations
    for my $transform (@transforms)
    {
        my ($index_out, @funcs) = @$transform;
        foreach my $func(@funcs)
        {
            $f[$index_out] = $func->($f[$index_out]);
        }
    }

    print "@f\n";
}






sub parse_transform_funcs
{
    sub parse_transform_func
    {
        # Takes in a function name, and outputs a list
        #
        #     (perl function, awk function text to print, extra awk
        #     condition/command directives)
        my $f = shift;

        if( $f eq 'us2s' )
        {
            return
              ( sub { return $_[0] * 1e-6; },
                '___input___ * 1e-6' );
        }
        elsif( $f eq 'deg2rad' )
        {
            return
              ( sub { return $_[0] * 3.141592653589793/180.0; },
                '___input___ * 3.141592653589793/180.0' );
        }
        elsif( $f eq 'rad2deg' )
        {
            return
              ( sub { return $_[0] * 180.0/3.141592653589793; },
                '___input___ * 180.0/3.141592653589793' );
        }
        elsif( $f eq 'rel' )
        {
            # relative to the starting value. The 'state' variable should be a
            # different instance for each sub instance
            return
              ( sub
                {
                    state $x0;
                    $x0 //= $_[0];
                    return $_[0] - $x0;
                },

                # statement to print
                '___input___ - ___state___',

                # preceding awk stanza
                '!___state___set {___state___ = ___input___; ___state___set=1}'
              );
        }
        elsif( $f eq 'diff' )
        {
            # relative to the previous value. The 'state' variable should be a
            # different instance for each sub instance
            return
              ( sub
                {
                    state $xprev;
                    my $ret = 0;
                    if (defined $xprev)
                    {
                        $ret = $_[0] - $xprev;
                    }
                    $xprev = $_[0];
                    return $ret;
                },

                # statement to print
                '(___input___ - ___state___)*___state__set',

                # preceding awk stanza
                undef,

                # following awk stanza
                '{___state___ = ___input___; ___state__set=1}'
              );
        }
        else
        {
            die "Unknown transform function '$f'";
        }
    }


    my @func_names = @_;
    my @perl_funcs;
    my $awk_statement = '___input___';
    my ($awk_stanzas_before, $awk_stanzas_after);
    for my $f(@func_names)
    {
        # get the perl functions, the awk statement text, and any awk stanzas we
        # need
        my ($p, $a, $s_before, $s_after) = parse_transform_func($f);

        # the perl functions go into a list, to be applied one at a time during
        # data processing
        push @perl_funcs, $p;

        # the awk function composition happens right now when I generate the awk
        # statement string
        state $awk_state_idx = 0;
        my $state = "__state$awk_state_idx";
        $a =~ s/___input___/$awk_statement/g;
        $a =~ s/___state___/$state/g;

        if( defined $s_before )
        {
            $s_before =~ s/___input___/$awk_statement/g;
            $s_before =~ s/___state___/$state/g;
            $awk_stanzas_before  .= " $s_before ";
        }
        if( defined $s_after )
        {
            $s_after =~ s/___input___/$awk_statement/g;
            $s_after =~ s/___state___/$state/g;
            $awk_stanzas_after  .= " $s_after ";
        }

        $awk_statement = $a;
        $awk_state_idx++;
    }

    return (@perl_funcs, $awk_statement, $awk_stanzas_before, $awk_stanzas_after);
}

sub makeAwkProgram
{
    # The awk program I generate here is analogous to the logic in the data
    # while() loop above


    my $awkprogram = '';

    # skip comments
    $awkprogram .=
      '/^#/ { ' . ($options{skipcomments} ? '' : 'print; ') . 'next } ';

    # skip incomplete records. Can happen if a log line at the end of a file
    # was cut off in the middle
    $awkprogram .=
      (1+$indices_in_max) . " > NF { next } ";

    # skip records that have empty input columns that must be non-empty
    if (@must_have_col_indices_in)
    {
        $awkprogram .=
          join(' || ', map { '$'.($_+1). " == \"-\"" } @must_have_col_indices_in);
        $awkprogram .= ' { next } ';
    }

    for my $expr( @{$options{matches}} )
    {
        $expr =~ s/(\w+)/defined $colindices_in{$1} ? '$' . ($colindices_in{$1}+1) : $1/eg;
        $awkprogram .= ' !' . "($expr) { next } ";
    }

    # skip empty records if we must
    if ($options{skipempty})
    {
        $awkprogram .=
          join ' && ', (map { '$'.($_+1)." == \"-\"" } @indices_in);
        $awkprogram .= ' { next } ';
    }

    # print selected fields. These already have the transformations applied
    $awkprogram .= $awk_state_stanzas_before if defined $awk_state_stanzas_before;
    $awkprogram .=
      '{ print ' . (join(',', @awk_output_fields)) . '} ';
    $awkprogram .= $awk_state_stanzas_after if defined $awk_state_stanzas_after;

    return $awkprogram;
}

# Reads a line from STDIN one byte at a time. This means that as far as the OS
# is concerned we never read() past our line. And when we exec() to awk, all the
# data is available. This is inefficient, but we only use this function to read
# up to the legend, which is fine.
sub get_unbuffered_line
{
    my $fd = shift;

    my $line = '';

    while(1)
    {
        my $c = '';
        return undef unless 1 == sysread($fd, $c, 1);

        $line .= $c;
        return $line if $c eq "\n";
    }
}
__END__

=head1 NAME

asciilog-filter - filters ascii logs to select particular rows, fields

=head1 SYNOPSIS

    # Read log data, filter out the timestamps, and post-process some of them
    $ raw-log-read-ins /tmp/stereo_lump_log |
      asciilog-filter '.*time' 'us2s(time)' 'rel(time)' 'rel(us2s(.*time))'

    # frame_time time us2s(time) rel(time) rel(us2s(frame_time)) rel(us2s(time))
    1434662133270338 1434662131279978 1434662131.27998 0 0 0
    1434662133270338 1434662131289978 1434662131.28998 10000 0 0.00999999046325684
    1434662133270338 1434662131299978 1434662131.29998 20000 0 0.0199999809265137
    1434662133270338 1434662131309978 1434662131.30998 30000 0 0.0299999713897705
    ...

    # Read log data, filter out the lat/lon, and make a plot
    $ raw-log-read-ins /tmp/stereo_lump_log |
      asciilog-filter lat lon |
      feedgnuplot --domain --lines

    [ plot pops up ]


=head1 DESCRIPTION

This tool reads in an ASCII data stream, and allows easy filtering to select
particular data from this stream. Many common post-processing operations are
available.

This is a UNIX-style tool, so the input/output of this tool is strictly
STDIN/STDOUT. Furthermore, this tool is a filter, so the format of the output is
I<exactly> the same as the format of the input.

This tool is convenient both to filter stored data, or to filter live data that
can then be plotted to produce realtime telemetry.

This tool takes a list of fields on the commandline. These are the only fields
that are selected for output. The requested field names are compared with the
fields listed in the legend of the data. If an exact match is found, we select
that column. Otherwise we run a regex search, and take all matching columns.

The user often wants to apply unit conversions to data, or to look at the data
relative to the initial point, or to differentiate the input. These filters can
be easily applied by this tool.

=head2 Input/output data format

The input/output data is simply an ASCII table of values. Any lines beginning
with C<##> are treated as comments, and are passed through. The first line that
begins with C<#> but not C<##> is a I<legend> line. After the C<#>, follow
whitespace-separated ASCII field names. Each subsequent line is
whitespace-separated values matching this legend. For instance, this is a valid
data file:

    ## log version: 3 ins_type: RAW_LOG_INS_440 camera_type: Unknown camera_type id: 5
    ## camera 0: serial 0,1 cols/rows: 3904 3904 channels: 1 depth: 8
    ## camera 1: serial 2,3 cols/rows: 3904 3904 channels: 1 depth: 8
    ## camera 2: serial 4,0 cols/rows: 3904 3904 channels: 1 depth: 8
    ## camera 3: serial 0,0 cols/rows: 0 0 channels: 0 depth: 0
    # x_rate y_rate z_rate
    -0.016107 0.004362 0.005369
    -0.017449 0.006711 0.006711
    -0.018456 0.014093 0.006711
    -0.017449 0.018791 0.006376

This is the format for both the input and the output. This tool makes sure to
update the legend to reflect which columns have been selected.

A string C<-> is used to indicate that a record does not have a value for this
field. Other records (lines) may have such a value.

=head2 Filters

We can post-process our data with filters. To apply filter =f= and then filter
=g= to column =x=, pass in =g(f(x))=. The filters currently available are

=over

=item C<us2s>

convert microseconds to seconds

=item C<deg2rad>

convert degrees to radians

=item C<rad2deg>

convert radians to degrees

=item C<rel>

report data relative to first value

=item C<diff>

report data relative to previous value

=back

=head2 Backend choice

By default, the parsing of arguments and the legend happens in perl, which then
constructs a simple awk script, and invokes C<awk> to actually read the data and
to process it. This is done because awk is lighter weight and runs faster, which
is important because our data sets could be quite large. This is especially true
of C<mawk>, which is noticeably more snappy than C<gawk>. We don't need the
extra features of C<gawk>, so C<mawk> is preferred here. If for whatever reason
we want to do everything with perl, this can be requested with the C<--perl>
option.

=head1 ARGUMENTS

=head2 --has a,b,c,...

Used to select particular records (rows) in a data file. A I<null> value in a
column is designated with a single C<->. This means that this particular field
value does not exist in this record. If we want to select only records that
I<do> have a column named C<x>, we can pass C<--has x>. The C<--has> option can
be repeated to request multiple columns, or the multiple columns can be given in
a whitespace-less comma-separated list. For instance if we want only records
that have both columns C<x> and C<y> we can pass in C<--has x,y>.

=head2 --matches expr

Used to select particular records (rows) in a data file. The argument is an
expression that is evaluated for each row. If it evaluates to true, that row is
output. This expression is passed directly to the perl or awk backend, so be
aware of which one you are using. This feature is I<very> slow in perl, so awk
is strongly recommended here. To refer to a field named C<xxx> in the
expression, simply say C<xxx>; do I<not> use a sigil. This will be added
automatically if the perl backend is used.

Multiple C<--matches> options can be given. The record is output onlyt if I<all>
the expressions are true.

=head2 --[no]skipempty

Do [not] skip records where all fields are blank. By default we I<do> skip all
empty records; to include them, pass C<--noskipempty>

=head2 --skipcomments

Don't output non-legend comments

=head2 --perl

Normally we initialize with perl, and use awk to do all the actual work. If we
want to do everything with perl, pass this option. It should produce the same
results, but not as quickly.

=head2 --dumpawk

All the work is generally done by an awk script that's generated on the fly from
the commandline options and the legend. For debugging it is possible to print
out the awk script instead of running it. This option does this.

=head2 --dumpindices

This option exists only for debugging. If given, prints out the indices of all
the selected columns, and exits.

=head1 REPOSITORY

https://github.jpl.nasa.gov/maritime-robotics/asciilog/

=head1 AUTHOR

Dima Kogan C<< <Dmitriy.Kogan@jpl.nasa.gov> >>

=head1 LICENSE AND COPYRIGHT

Proprietary. Copyright 2016 California Institute of Technology
