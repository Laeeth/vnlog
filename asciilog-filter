#!/usr/bin/perl
use strict;
use warnings;
use Getopt::Long qw(:config no_getopt_compat);
use List::Util 'max';
use List::MoreUtils qw(any all);
use FindBin '$Bin';
use lib "$Bin/lib";
use Asciilog::Util 'get_unbuffered_line';

use feature qw(say state);


my $usage =  <<EOF;
$0 [--has c0,c1,...] [--has c2] [--print|--pick|-p c3,+c4,sum=c5+c6,rel(c7)] [match_expr] [match_expr] ...

    Other available options:
      --eval expr
      --noskipempty
      --skipcomments
      --dumpexprs
      --perl
      --unbuffered

    This tool is a nicer 'awk' that reads and write asciilog. As a result, it
    can refer to columns by name, not number, like awk does.

    Columns are selected with -p (we select all columns if omitted). We can
    rename columns with C<=>, and if we do that, we can output arbitrary
    expressions. For instance:

      asciilog-filter -p 'a,b,sum=a+b'

    Rows are selected with match expressions given on the commandline. To select
    all rows after a certain time, and within a certain temperature range, do:

      asciilog-filter 'time > 100' 'temp > 20 && temp < 30'

    By default, this tool generates an awk script that's then interpreted by
    mawk. Although it is slower, perl can be used instead by passing --perl.
    This makes no difference in output in most cases, but the various
    expressions would be evaluated by perl, which could be desirable.

    --unbuffered flushes each line after each print. Useful for streaming data.

    For more information, please read the manpage.
EOF

if(! @ARGV)
{
    die $usage;
}

# by default we do skip empty records
my %options = (skipempty => 1);
GetOptions(\%options,
           "has=s@",
           "pick|print|p=s@",
           "eval=s",
           "skipempty!",
           "skipcomments!",
           "dumpexprs!",
           "perl",
           "unbuffered",
           "help") or die($usage);
if( defined $options{help} )
{
    print $usage;
    exit 0;
}

$options{has}  //= [];
$options{pick} //= [];

# anything remaining on the commandline are 'matches' expressions
$options{matches} = \@ARGV;

if( defined $options{eval} )
{
    $options{skipcomments} = 1;
}

if( defined $options{eval} && @{$options{pick}} )
{
    say STDERR "--eval is given, so no column selectors should be given also";
    die $usage;
}

# parse the , in $options{has} and $options{pick}
for my $listkey (qw(has pick))
{
    @{$options{$listkey}} = map split(/,/, $_), @{$options{$listkey}};
}

# any requested columns preceded with '+' go into --has. And I strip out the '+'
for my $ipick(0..$#{$options{pick}})
{
    # handle extra column syntax here
    if( ${$options{pick}}[$ipick] =~ /^\+(.+)/ )
    {
        ${$options{pick}}[$ipick] = $1;
        push @{$options{has}}, ${$options{pick}}[$ipick];
    }
}

my @picked_exprs_named  = @{$options{pick}};
my @must_have_col_names = @{$options{has}};
my @must_have_col_indices_input;

# if no columns requested, just print everything
if( !@picked_exprs_named && !@must_have_col_names && !@{$options{matches}} && !defined $options{eval} )
{
    while(<STDIN>)
    {
        print;
        flush STDOUT if $options{unbuffered};
    }
}

my @colnames_output;

# input column-name to index map. If I have more than one of the same column,
# this maps to undef. Not an error unless we try to use the columns
my %colindices_input;

my $colidx_needed_max = -1;



# awk or perl strings representing stuff to output. These are either simple
# column references (such as $1), or more complex expressions
my @langspecific_output_fields;

# How many rel(),diff() calls we have. I generate code based on this
my $Nrel  = 0;
my $Ndiff = 0;


# Loop searching for the legend.
#
# Here instead of using while(<STDIN>) we read one byte at a time. This means
# that as far as the OS is concerned we never read() past our line. And when we
# exec() to awk, all the data is available. This is inefficient, but we only use
# this function to read up to the legend, which is fine.
#
# Note that perl tries to make while(<STDIN>) work by doing an lseek() before we
# exec(), but if we're reading a pipe, this can't work
while(defined ($_ = get_unbuffered_line(*STDIN)))
{
    # I pass through (don't treat as a legend) ## comments and #! shebang
    if(/^#[#!]/p)
    {
        unless($options{skipcomments})
        {
            print;
            flush STDOUT if $options{unbuffered};
        }
        next;
    }

    if( /^#/p )
    {
        chomp;

        # we got a legend line
        my @cols_all_legend_input = split ' ', ${^POSTMATCH}; # split the field names (sans the #)
        foreach my $idx (0..$#cols_all_legend_input)
        {
            if( exists $colindices_input{$cols_all_legend_input[$idx]} )
            {
                $colindices_input{$cols_all_legend_input[$idx]} = undef;
            }
            else
            {
                $colindices_input{$cols_all_legend_input[$idx]} = $idx;
            }
        }

        # If we weren't asked for particular columns, take them all. This isn't
        # a no-op because we can have --has
        @picked_exprs_named = @cols_all_legend_input unless @picked_exprs_named;

      COLUMN:
        foreach my $picked_expr_named (@picked_exprs_named)
        {
            my $accept = sub
            {
                my ($exprs, $name) = @_;

                if( defined $name )
                {
                    if( @$exprs != 1 )
                    {
                        die "A named expression can only refer to ONE column";
                    }
                    push @colnames_output, $name;
                }
                else
                {
                    push @colnames_output, @$exprs;
                }

                my @output_fields;
                for my $expr(@$exprs)
                {
                    $Nrel  = subst_rel (\$expr);
                    $Ndiff = subst_diff(\$expr);

                    my ($output_field, $colidx_needed_max_here) =
                      expr_subst_col_names($options{perl} ? 'perl' : 'awk',
                                           $expr);
                    if ( $colidx_needed_max_here > $colidx_needed_max )
                    {
                        $colidx_needed_max = $colidx_needed_max_here;
                    }
                    push @output_fields, $output_field;
                }
                push @langspecific_output_fields, @output_fields;
            };







            my ($name, $picked_expr) = $picked_expr_named =~ /(.*?)=(.*)/;
            if( !defined $picked_expr )
            {
                $picked_expr = $picked_expr_named;
            }


            # do I have an exact column match?
            if( defined $colindices_input{$picked_expr} )
            {
                # We have exactly ONE matched column
                $accept->( [$picked_expr], $name);
                next;
            }
            if( exists $colindices_input{$picked_expr} )
            {
                die "Found more than one column that string-matched '$picked_expr' exactly";
            }

            # No exact column match. If this is a named expression, I pass it on
            # to awk/perl
            if( defined $name )
            {
                $accept->([$picked_expr], $name);
                next;
            }

            # No exact matches were found, and not a named expression. Let me
            # try a regex
            my $picked_expr_re;
            eval { $picked_expr_re = qr/$picked_expr/; };
            if( !$@ )
            {
                # compiled regex successfully
                my @matching_input_cols = grep /$picked_expr_re/, @cols_all_legend_input;
                if( @matching_input_cols >= 1 )
                {
                    $accept->(\@matching_input_cols);
                    next;
                }
            }

            die "Couldn't find requested column '$picked_expr' in the legend line '$_'";
        }

        # print out the new legend
        unless($options{dumpexprs} || $options{eval})
        {
            print "# @colnames_output\n";
            flush STDOUT if $options{unbuffered};
        }


        if( @must_have_col_names )
        {
            foreach my $col (@must_have_col_names)
            {
                if( !defined $colindices_input{$col})
                {
                    die "I don't have column '$col'";
                }
                push @must_have_col_indices_input, $colindices_input{$col};
            }
        }
        last;
    }

    die "Got data line before a legend";
}

if(!%colindices_input)
{
    die "No legend received. Is the input file empty?";
}






# At this point I'm done dealing with the legend, and it's time to read in and
# process the data. I can keep going in perl, or I can generate an awk program,
# and let awk do this work. The reason: awk (mawk especialy) runs much faster.
# Both paths should produce the exact same output, and the test suite makes sure
# this is the case

if( !$options{perl} )
{
    my $awkprogram = makeAwkProgram();
    if( $options{dumpexprs} )
    {
        say $awkprogram;
        exit;
    }
    if($options{unbuffered})
    {
        exec 'mawk', '-Winteractive', $awkprogram;
    }
    else
    {
        exec 'mawk', $awkprogram;
    }

    exit; # dummy. We never get here
}

sub expr_subst_col_names
{
    # I take in a string with awk/perl code, and replace field references to
    # column references that the awk/perl program will understand. To minimize
    # the risk of ambiguous matches, I try to match longer strings first
    my ($language, $out) = @_;

    my $colidx_needed_max_here = -1;

    for my $key(reverse sort {length($a) <=> length($b)} keys %colindices_input)
    {
        if( $language eq 'perl' )
        {
            my $post = $key =~ /\w$/ ? '\b' : '';
            my $re = qr/\Q$key\E$post/;
            my $found = $out =~ s/$re/\$f->[$colindices_input{$key}]/g;

            if($found && $colindices_input{$key} > $colidx_needed_max_here)
            {
                $colidx_needed_max_here = $colindices_input{$key};
            }
        }
        elsif( $language eq 'awk' )
        {
            # column index that awk knows about
            my $colidx = $colindices_input{$key} + 1;
            my $re = qr/\b$key\b/;
            my $found = $out =~ s/$re/\$$colidx/g;

            if($found && $colindices_input{$key} > $colidx_needed_max_here)
            {
                $colidx_needed_max_here = $colindices_input{$key};
            }
        }
        else
        {
            die "Unknown language '$language";
        }
    }
    return ($out, $colidx_needed_max_here);
}

sub subst_rel
{
    my ($expr) = @_;

    state $relidx = 0;

    while( $$expr =~ /\brel\s*\(/ )
    {
        $$expr =~ s/\brel(\s*\()/rel$relidx$1/;
        $relidx++;
    }
    return $relidx;
}
sub subst_diff
{
    my ($expr) = @_;

    state $diffidx = 0;

    while( $$expr =~ /\bdiff\s*\(/ )
    {
        $$expr =~ s/\bdiff(\s*\()/diff$diffidx$1/;
        $diffidx++;
    }
    return $diffidx;
}


my $must_match_expr =
  join ' && ',
  map { my ($outexpr) = expr_subst_col_names( 'perl', $_); $outexpr; }
  @{$options{matches}};
$must_match_expr = 1 if !defined $must_match_expr || '' eq $must_match_expr;

my $evalstr = 'sub matches { my ($f) = @_; return ' . $must_match_expr . '; }';

if ( $options{eval} )
{
    my ($expr) = expr_subst_col_names( 'perl', $options{eval} );
    $evalstr .= "\n" . 'sub evalexpr { my ($f) = @_; ' . $expr . ' ; }';
}

$evalstr .=
  "\n" . 'sub compute_output_fields { my ($f) = @_; return [' . join(',', @langspecific_output_fields) . ']; }';






if( $options{dumpexprs} )
{
    say "Expressions to evaluate:\n\n$evalstr";
    exit;
}

no strict;
no warnings;
eval $evalstr;
if( $@ )
{
    die "Error evaluating expression '$evalstr':\n$@";
}
use strict;
use warnings;


# I'm defining the rel()/diff() functions. These should be global, so if I do
# this inside a for(){}, the functions end up local to that for(). I thus have
# an ugly manual loop
my $i = 0;
EVAL_REL_FUNC:
eval "sub rel$i" . '{ my ($x) = @_; state $state=undef; if(!defined $state) { $state=$x; } return $x - $state; } ';
if($i++ < $Nrel) { goto EVAL_REL_FUNC; }

$i = 0;
EVAL_DIFF_FUNC:
eval "sub diff$i" . '{ my ($x) = @_; state $inited=0; state $state=0; my $retval = ($x - $state)*$inited; $state = $x; $inited=1; return $retval; } ';
if($i++ < $Ndiff) { goto EVAL_DIFF_FUNC; }


RECORD:
while(<STDIN>)
{
    # Data loop. Each statement here is analogous to the awk program generated
    # by makeAwkProgram();

    # skip comments
    if(/^#/)
    {
        unless($options{skipcomments})
        {
            print;
            flush STDOUT if $options{unbuffered};
        }
        next;
    }

    chomp;
    my @f = map {q{-} eq $_ ? undef : $_ } split;

    # skip incomplete records. Can happen if a log line at the end of a file was
    # cut off in the middle
    next unless $colidx_needed_max <= $#f;

    # skip records that have empty input columns that must be non-empty
    next if any {!defined $f[$_]} @must_have_col_indices_input;

    # skip all records that don't match given expressions
    next unless matches(\@f);

    if( $options{eval} )
    {
        evalexpr(\@f);
    }
    else
    {
        my $fout = compute_output_fields(\@f);

        # skip empty records if we must
        next if $options{skipempty} && all {!defined $_} @$fout;

        say join(' ', map {$_ // '-'} @$fout);
        flush STDOUT if $options{unbuffered};
    }
}










sub makeAwkProgram
{
    # The awk program I generate here is analogous to the logic in the data
    # while() loop above
    my $awkprogram = '';

    for my $i (0..$Nrel-1)
    {
        $awkprogram .= "function rel$i(x) { if(!__inited_rel$i) { __state_rel$i = x; __inited_rel$i = 1; } return x - __state_rel$i; } ";
    }
    for my $i (0..$Ndiff-1)
    {
        $awkprogram .= "function diff$i(x) { retval = (x - __state_diff$i)*__inited_diff$i; __state_diff$i = x; __inited_diff$i = 1; return retval; } ";
    }


    # skip comments
    $awkprogram .=
      '/^#/ { ' . ($options{skipcomments} ? '' : 'print; ') . 'next } ';

    # skip incomplete records. Can happen if a log line at the end of a file
    # was cut off in the middle
    $awkprogram .= (1+$colidx_needed_max) . " > NF { next } ";

    # skip records that have empty input columns that must be non-empty
    if (@must_have_col_indices_input)
    {
        $awkprogram .=
          join(' || ', map { '$'.($_+1). " == \"-\"" } @must_have_col_indices_input);
        $awkprogram .= ' { next } ';
    }

    for my $expr( @{$options{matches}} )
    {
        ($expr) = expr_subst_col_names('awk', $expr);
        $awkprogram .= ' !' . "($expr) { next } ";
    }

    if( $options{eval} )
    {
        my ($expr) = expr_subst_col_names('awk', $options{eval});
        $awkprogram .= "$expr ";
    }
    else
    {
        # skip empty records if we must. I evaluate the fields just one time to
        # not affect the state inside rel() and diff()
        if (!$options{skipempty})
        {
            # print selected fields
            $awkprogram .=
              '{ print ' . (join(',', @langspecific_output_fields)) . ' } ';
        }
        else
        {
            # I evaluate and cache all the fields
            $awkprogram .=
              '{ ' .
              join(' ',
                   map { "__f$_ = $langspecific_output_fields[$_]; " }
                   0..$#langspecific_output_fields) .

                     # Then I do skipempty. Important to do this after evaluating ALL the
                     # fields to tick all the rel(), diff() state
                     "if(" . join( ' && ', map { "__f$_  == \"-\""} 0..$#langspecific_output_fields ) .
                     ") { next }; " .

                     # And THEN I print everything
                     'print ' . (join(',', map {"__f$_"} 0..$#langspecific_output_fields)) . '} ';
        }
    }

    return $awkprogram;
}

__END__

=head1 NAME

asciilog-filter - filters asciilogs to select particular rows, fields

=head1 SYNOPSIS

 $ cat run.asciilog

 # time x   y   z   temperature
 1      1   2.3 4.8 30
 2      1.1 2.2 4.7 31
 3      1   2.0 4.0 35
 4      1   1.6 3.1 42


 $ <run.asciilog asciilog-filter -p x,y,z | asciilog-align

 # x y   z
 1   2.3 4.8
 1.1 2.2 4.7
 1   2.0 4.0
 1   1.6 3.1


 $ <run.asciilog asciilog-filter -p time,'dist=sqrt(x*x + y*y + z*z)' | asciilog-align

 # time dist
 1      5.41572
 2      5.30471
 3      4.58258
 4      3.62905


 $ <run.asciilog asciilog-filter 'temperature >= 35' | asciilog-align

 # time x y   z   temperature
 3      1 2.0 4.0 35
 4      1 1.6 3.1 42

 $ <run.asciilog asciilog-filter --eval '{s += temperature} END { print "mean temp: " s/NR}'

 mean temp: 34.5


 $ <run.asciilog asciilog-filter -p x,y | feedgnuplot --terminal 'dumb 80,30' --unset grid --domain --lines --exit

   2.3 +---------------------------------------------------------------------+
       |           +          +          ***************         +           |
       |                                                **************       |
       |                                                              *******|
   2.2 |-+                                                       ************|
       |                                                 ********            |
       |                                         ********                    |
   2.1 |-+                              *********                          +-|
       |                        ********                                     |
       |                ********                                             |
       |            ****                                                     |
     2 |-+         *                                                       +-|
       |           *                                                         |
       |           *                                                         |
       |           *                                                         |
   1.9 |-+         *                                                       +-|
       |           *                                                         |
       |           *                                                         |
       |           *                                                         |
   1.8 |-+         *                                                       +-|
       |           *                                                         |
       |           *                                                         |
   1.7 |-+         *                                                       +-|
       |           *                                                         |
       |           *                                                         |
       |           *          +           +           +          +           |
   1.6 +---------------------------------------------------------------------+
      0.98         1         1.02        1.04        1.06       1.08        1.1



=head1 DESCRIPTION

This tool is largely a frontend for awk to operate on asciilog files. Asciilog
is both an input and an output. This tool makes it very simple to select
specific rows and columns for output and to manipulate the data in various ways.

This is a UNIX-style tool, so the input/output of this tool is strictly
STDIN/STDOUT. Furthermore, in its usual form this tool is a filter, so the
format of the output is I<exactly> the same as the format of the input. The
exception to this is when using C<--eval>, in which the output is dependent on
whatever expression we're evaluating.

This tool is convenient to process both stored data or live data; in the latter
case, it's very useful to pipe the streaming output to C<feedgnuplot --stream>
to get a realtime visualization of the incoming data.

This tool reads enough of the input file to get a legend, at which point it
constructs an awk program to do the main work, and execs to awk (it's possible
to use perl as well, but this isn't as fast).

=head2 Input/output data format

The input/output data is asciilog: a plain-text table of values. Any lines
beginning with C<#> are treated as comments, and are passed through. The first
line that begins with C<#> but not C<##> is a I<legend> line. After the C<#>,
follow whitespace-separated field names. Each subsequent line is
whitespace-separated values matching this legend. For instance, this is a valid
asciilog file:

 ## comment comment comment
 ## more comments
 # x y z
 -0.016107 0.004362 0.005369
 -0.017449 0.006711 0.006711
 -0.018456 0.014093 0.006711
 -0.017449 0.018791 0.006376

C<asciilog-filter> uses this format for both the input and the output. The
comments are preserved, but the legend is updated to reflect the fields in the
output file.

A string C<-> is used to indicate an undefined value, so this is also a valid
asciilog file:

 # x y z
 1 2 3
 4 - 6
 - - 7

=head2 Filtering

To select specific I<columns>, pass their names to the C<-p> option (short for
C<--print> or C<--pick>, which are synonyms). In its simplest form, to grab only
columns C<x> and C<y>, do

 asciilog-filter -p x,y

See the detailed description of C<-p> below for more detail.

To select specific I<rows>, we use I<matches> expressions. Anything on the
C<asciilog-filter> commandline and not attached to any C<--xxx> option is such
an expression. For instance

 asciilog-filter 'size > 10'

would select only those rows whose C<size> column contains a value E<gt> 10. See
the detailed description of matches expressions below for more detail.

=head2 Backend choice

By default, the parsing of arguments and the legend happens in perl, which then
constructs a simple awk script, and invokes C<mawk> to actually read the data
and to process it. This is done because awk is lighter weight and runs faster,
which is important because our data sets could be quite large. We default to
C<mawk> specifically, since this is a simpler implementation than C<gawk>, and
runs much faster. If for whatever reason we want to do everything with perl,
this can be requested with the C<--perl> option.

=head2 Special functions

For convenience we support two special functions in any expression passed on to
awk or perl (named expressions, matches expressions, C<--eval> strings). These are

=over

=item *

C<rel(x)> returns value of C<x> relative to the first value of C<x>. For
instance we might want to see the time or position relative to the start, not
relative to some absolute beginning. Example:

 $ cat tst.asciilog

 # time x
 100    200
 101    212
 102    209


 $ <tst.asciilog asciilog-filter -p 't=rel(time),x=rel(x)

 # t x
 0 0
 1 12
 2 9

=item *

C<diff(x)> returns the difference between the current value of C<x> and the
previous value of C<x>. Example:

 $ cat tst.asciilog

 # x
 1
 8
 27
 64
 125


 $ <tst.asciilog asciilog-filter -p 'd1=diff(x),d2=diff(diff(x))'

 # d1 d2
 0 0
 7 7
 19 12
 37 18
 61 24

=back

=head1 ARGUMENTS

=head2 -p|--print|--pick expr

These option provide the mechanism to select specific columns for output. For
instance to pull out columns called C<lat>, C<lon>, and any column whose name
contains the string C<feature_>, do

 asciilog-filter -p lat,lon,'feature_.*'

or, equivalently

 asciilog-filter --print lat --print lon --print 'feature_.*'

We look for exact column name matches first, and if none are found, we try a
regex. If there was no column called exactly C<feature_>, then the above would
be equivalent to

 asciilog-filter -p lat,lon,feature_

This mechanism is much more powerful than just selecting columns. First off, we
can rename chosen fields:

 asciilog-filter -p w=feature_width

would pick the C<feature_width> field, but the resulting column in the output
would be named C<w>. When renaming a column in this way regexen are I<not>
supported, and exact field names must be given. But the string to the right of
the C<=> is passed on directly to awk (after replacing field names with column
indices), so any awk expression can be used here. For instance to compute the
length of a vector in separate columns C<x>, C<y>, and C<z> you can do:

 asciilog-filter -p 'l=sqrt(x*x + y*y + z*z)'

A single column called C<l> would be produced.

=head2 --has a,b,c,...

Used to select records (rows) that have a non-empty value in a particular field
(column). A I<null> value in a column is designated with a single C<->. If we
want to select only records that have a value in the C<x> column, we pass
C<--has x>. To select records that have data for I<all> of a given set of
columns, the C<--has> option can be repeated, or these multiple columns can be
given in a whitespace-less comma-separated list. For instance if we want only
records that have data in I<both> columns C<x> I<and> C<y> we can pass in
C<--has x,y> or C<--has x --has y>. If we want to combine multiple columns in an
I<or> (select rows that have data in I<any> of a given set of columns), use a
matches expression, as documented below.

If we want to select a column I<and> pick only rows that have a value in this
column, a shorthand syntax exists:

 asciilog-filter --has col -p col

is equivalent to

 asciilog-filter -p +col

=head2 Matches expressions

Anything on the commandline not attached to any C<--xxx> option is a I<matches>
expression. These are used to select particular records (rows) in a data file.
For each row, we evaluate all the expressions. If I<all> the expressions
evaluate to true, that row is output. This expression is passed directly to the
awk (or perl) backend.

Example: to select all rows that have valid data in column C<a> I<or> column
C<b> I<or> column C<c> you can

 asciilog-filter 'a != "-" || b != "-" || c != "-"'

or

 asciilog-filter --perl 'defined a || defined b || defined c'

As with the named expressions given to C<-p> (described above), these are passed
directly to awk, so anything that can be done with awk is supported here.

=head2 --eval expr

Instead of printing out all matching records and picked columns, just run the
given chunk of awk (or perl). In this mode of operation, C<asciilog-filter> acts
just like a glorified awk, that allows fields to be accessed by name instead of
by number, as it would be in raw awk.

Since the expression may print I<anything> or nothing at all, the output in this
mode is not necessarily itself a valid asciilog stream. And no column-selecting
arguments should be given, since they make no sense in this mode.

In awk the expr is a full set of pattern/action statements. So to print the sum
of columns C<a> and C<b> in each row, and at the end, print the sum of all
values in the C<a> column

 asciilog-filter --eval '{print a+b; suma += a} END {print suma}'

In perl the arbitrary expression fits in like this:

 while(<>) # read each line
 {
   next unless matches; # skip non-matching lines
   eval expression;     # evaluate the arbitrary expression
 }

=head2 --[no]skipempty

Do [not] skip records where all fields are blank. By default we I<do> skip all
empty records; to include them, pass C<--noskipempty>

=head2 --skipcomments

Don't output non-legend comments

=head2 --perl

By default all procesing is performed by C<mawk>, but if for whatever reason we
want perl instead, pass C<--perl>. Both modes work, but C<mawk> is noticeably
faster. C<--perl> could be useful because it is more powerful, which could be
important since a number of things pass commandline strings directly to the
underlying language (named expressions, matches expressions, C<--eval> strings).
Note that while variables in perl use sigils, column references should I<not>
use sigils. To print the sum of all values in column C<a> you'd do this in awk

 asciilog-filter --eval '{suma += a} END {print suma}'

and this in perl

 asciilog-filter --perl --eval '{$suma += a} END {say $suma}'

The perl strings are evaluated without C<use strict> or C<use warnings> so I
didn't have to declare C<$suma> in the example.

=head2 --dumpexprs

Used for debugging. This spits out all the expressions parsed from the
commandline.

=head2 --unbuffered

Flushes each line after each print. This makes sure each line is output as soon
as it is available, which is crucial for realtime output and streaming plots.

=head1 REPOSITORY

https://github.com/dkogan/asciilog/

=head1 AUTHOR

Dima Kogan C<< <dima@secretsauce.net> >>

=head1 LICENSE AND COPYRIGHT

Copyright 2016-2017 California Institute of Technology
Copyright 2017-2018 Dima Kogan C<< <dima@secretsauce.net> >>


This library is free software; you can redistribute it and/or modify it under
the terms of the GNU Lesser General Public License as published by the Free
Software Foundation; either version 2.1 of the License, or (at your option) any
later version.

=cut
